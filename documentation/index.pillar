!TaskIT docs


!!Lazy result resolution

A third way to work with futures is to ask them for a lazy result. A lazy result is an object that represents, almost transparently, the value of the task execution. This lazy result will be (using some reflective Pharo facilities) the value of the result once it is available, or under demand (for example, when a message is sent to it). Lazy results support a style of programming that is close to the synchronous style, while performing asynchronously if the result is not used. 

[[[
future := [ employee computeBaseSallary ] shootIt.
result := future asResult.

subTotal := employee sumSallaryComponents

result + subTotal
]]]

@@comment explain the code

Note: Lazy results are to be used with care. They use Pharo's ==become:== facility, and so, it will scan the system to update object references.

Lazy results can be used to easily synchronize tasks. One task running in parallel with another one and waiting for it to finish can use a lazy result object to perform transparently as much work as it can in parallel and then get blocked waiting for the missing part. Only when the result object is sent a message the 

[[[
future := [ employee computeBaseSallary ] shootIt.
baseSallary := future asResult.

[ employee sumSallaryComponents + baseSallary ] shootIt value.
]]]

!!TaskIT runners

!!Into Task Runners

Task runners are in charge of the execution of tasks. They decide if a task executes in a separate process, in the same process, or in a process that is shared by many tasks. A task runner  schedule and prioritize tasks.

Task runners contract is based on the following messages:

- ""run:"" It is the main message a task runner implements. It receives as argument a task to run and provides a future as result.
- ""cancel"" This message tells the runner to stop executing the task. It will, if possible, cancel the execution and notify all provided futures of this.
- ""isRunning"" This is a testing message that indicates if a task runner is currently running.
- ""isTerminated"" This is a testing message that indicates if a task runner has finished its execution.

TaskIT provides already several task runners for simple and common tasks. In the following subsections we will provide an overview on each of them for normal usage.

!!! The one shot runner

A one shot runner, instance of ==TKTOneShotRunner==, is a task runner that is meant to run a single task in a separate Pharo process. The one shot runner will start a new process when the task is run, and so, handle the process' life cycle. A one shot runner, as it name says, is meant to be used once and be discarded. It should not be reused with several tasks.

The usage of a one shot runner is simple. We should create a new instance of it and send it the message ==run:== with the task to run as a parameter. The result of that message will be a future object.

[[[
runner := TKTOneShotRunner new.
future := runner run: [ (Delay forMilliseconds: 30000) wait ] asTask.
]]]

Since the usage of one shot runners is pretty common and straight forward, the ==shootIt== method of a task is a shortcut to it.

[[[
TKTTask >> shootIt
	
	^ TKTOneShotRunner new run: self
]]]

!!! The same process runner

The same process runner is a simple runner that executes a task in the caller process. This runner may come in handy to change the way a task runs in a transparent way, since it is polymorphic with the other task runners. A same process runner is reusable, since it holds no state.

[[[
runner := TKTSameProcessRunner new.
future := runner run: [ (Delay forMilliseconds: 30000) wait ] asTask.
]]]

Additionally, sending the ==value== message to a task is a shortcut to execute it with a same process runner.

[[[
TKTTask >> value
	" The future is dispendable in this case, cause is executing in the same thread "
	^ TKTSameProcessRunner new run: self
]]]



!!! Persistent runners

A persistent runner is a task runner that persists in time, executing many tasks. Persistent runners are associated to a unique Pharo process and manage its life-cycle. We can control the life-cicle of a persistent task runner with the following messages:

- ""start"" Starts the persistent runner and creates its associated process.
- ""stop"" Stops the persistent runner and kill its associated process.
- ""suspend"" Pauses the persistent runner. This can leave a task in the middle of an execution.
- ""resume"" Resumes a paused execution of the persistent runner.
- ""waitToFinish"" Will block the caller until the runner has finished to run.

Version 1 of TaskIT presents two flavors of persistent runners: the Looping Runner and the Worker Runner.


!!!! The looping runner

A looping runner is a task runner that will execute the same task over and over again iteratively. This runner, instance of ==TKTLoopingRunner==, is configured with the task and the amount of times it has to execute.
This looping runner will finish and kill its associated process once all its iterations are finished.

[[[
runner := TKTLoopingRunner new loopTimes: 20; yourself.
value := 0.
future := runner run: [ value := value + 1 ] asTask.
]]]

By default, if no loopTimes are configured, the looping runner will loop infinitely. When using a looping runner, the future will hold always the last value obtained from the task execution.


[[[
runner := TKTLoopingRunner new.
value := 0.
future := runner run: [ value := value + 1 ] asTask.

aSample := future value. 
1 second asDelay wait. 

self assert: future value > aSample. 
]]]


Note that we don't need to ==start== explicitly the loop runner. It will be started automatically by the ==run:== message.

!!!! The worker runner 


A worker is a runner instance of ==TKTWorker== that has a queue of tasks to execute. The worker runner will execute its tasks sequencially, according to its queue. To add a task into a worker's queue, we can schedule the task using the ==scheduleTask:== message. The ==spawn== message provides with a shortcut to create and start a new worker.

[[[
worker := TKTWorker spawn.
future := worker schedduleTask: [ 2+2 ] asTask.
self assert: future value = 4.
worker stop.
]]]

This kind of runner is mean for global system performance. By using workers, we can control the amount of alive processes and how tasks are distributed amongst them. For example, in the following example three tasks are executed in a separate process (which is the same process as it is the same worker), and we can still have a synchronousish style of programming.

[[[
worker := TKTWorker spawn .
future := worker scheduleTask: [ 2+2 ] asTask.
future2 := worker scheduleTask: [ 3+3 ] asTask.
future3 := worker scheduleTask: [ 1+1 ] asTask.
self assert: (future value + future2 value + future3 value) = 12.
worker stop.
]]]

You can create your own worker instances as shown in the examples, or also you can use it through the ==TKTTaskDispatcher== singleton worker pool.

!! Worker pools

A worker pool is our implementation of a threads pool. Its main purpose is to provide with several worker runners and decouple us from the management of threads/processes. Worker pools are built on top of TaskIT, inside the PoolIT package. A worker pool, instance of ==PITWorkersPool==, manages several worker runners. All runners inside a worker pool shared a single task queue. We can schedule a task for execution using the ==dispatch:== message.

[[[
dispatcher := PITWorkersPool instance. 
future := dispatcher dispatch: [ 1+1 ] asTask.
future value = 2
]]]		

By default, a worker pool spawns two workers during it initialization (which is lazy). We can add more workers to the pool with the ==addWorker== message and remove them with the ==removeWorker== message.

[[[
dispatcher := PITWorkersPool instance. 
dispatcher addWorker.
dispatcher
    removeWorker;
    removeWorker
]]]		

The ==removeWorker== message send will fail if there is no workers available to remove. The removed worker will stop after it finishes any task it is running, and it will not be available for usage any more. The last remaining reference to this worker is given as return of the message.

Finally, there is a fancy way to schedule tasks into the singleton pool of workers.

[[[
future := [ 2 + 2 ] scheduleIt. 
]]]

!!Customizing TaskIT

!!!Custom Tasks

When you need to customize a task, the most important thing is to mind the main invocation method. 
	
[[[  
runOnRunner: aRunner withFuture: aFuture

	| value |
	self setUpOnRunner: aRunner withFuture: aFuture.
	[
		[
			value := self executeWithFuture: aFuture. 
		] on: Error do: [ : exception |
			^ aRunner deployError: exception intoFuture: aFuture.
		].
		aRunner deployValue: value intoFuture: aFuture.
	] ensure: [
		self tearDownOnRunner: aRunner withFuture: aFuture.
		aRunner noteFutureHasFinished: aFuture.
	].
]]]

The task execution life cycle is defined here. 
	
It has a setup, execution and teardown	 time that is always executed. 
In this method we also have two important parts the deploy of the result (success or error) and the notification of a future as finished. (The future window is not just the task running, it is all the task execution life time. From the setup to the teardown).

So, if you need a task to setUp resources, or have some cleanup post processing, in the same process line, do not hesitate in subclassing and using this prepared hooks.  

[[[
TKTSubClassedTask>>#setUpOnRunner: aRunner withFuture: aFuture.
TKTSubClassedTask>>#tearDownOnRunner: aRunner withFuture: aFuture.
]]]

By other side, if what you need is to change the execution it self (Maybe the main invocation method is not really suitable for you), remember always to notice the runner about the finishing of an execution, by sending the proper notification inside your overridden method.

[[[
TKTSubClassedTask>>#runOnRunner: aRunner withFuture: aFuture
	"..."
	aRunner noteFutureHasFinished: aFuture.
	"..."
]]]